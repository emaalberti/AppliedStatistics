{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6cdc740",
   "metadata": {},
   "source": [
    "## Prediction of cancer types from gene expression data\n",
    "\n",
    "You are given a dataset consisting of gene expressions and cancer types for more than 6k patients.\n",
    "\n",
    "Data has already been pre-process as to keep only 150 gene expressions that are believed to correlate with the response.\n",
    "\n",
    "Your goal is to fit several classification models on this data\n",
    "\n",
    "\n",
    "Answer to the questions at the following link: https://forms.cloud.microsoft/e/pDz5AUes92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38de5f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059dd8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7044b7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv('tcga_150gene.csv')\n",
    "\n",
    "X = data.drop('label', axis=1).values\n",
    "y = data['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78b9a89",
   "metadata": {},
   "source": [
    "First we consider a binary classification problem, where we predict the most common cancer type against all the other cancer.\n",
    "\n",
    "Define y_binary to be 1 if patient is affected by the most common cancer type and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8784cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the most frequent cancer type\n",
    "most_common_label = y.value_counts().idxmax()\n",
    "y_binary = (y == most_common_label).astype(int).values\n",
    "\n",
    "# Split into training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_binary, test_size=0.3, random_state=42, stratify=y_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7feaf0c5",
   "metadata": {},
   "source": [
    "The test set should not be used for any statistical analysis except for comparing different models.\n",
    "\n",
    "First, let's scale the features as to have zero mean and unit variance. Work only on the scaled features from now on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bc5135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458fda23",
   "metadata": {},
   "source": [
    "### Fit a logistic regression with a mild Rigde penalty (shrinkage parameter=1e-6), max_iter=100000\n",
    "\n",
    "NB: be careful about what the shrinkage parameter represents in sklearn and what it means for us!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658d1856",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c25ee48",
   "metadata": {},
   "source": [
    "Q1: what is the f1-score for the predictions on the training set?\n",
    "\n",
    "Q2: what is the recall for the predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70056ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = None\n",
    "y_pred_test = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4f1e8d",
   "metadata": {},
   "source": [
    "## On to variable selection.\n",
    "\n",
    "First, perform step-wise variable selection based on the BIC score. The model is the same one as before (logistic regression with mild ridge penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cabc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some helper functions used to compute the BIC\n",
    "\n",
    "def count_params(model):\n",
    "    \"\"\"\n",
    "    Return the total number of parameters in the given fitted model.\n",
    "    \n",
    "    Supports:\n",
    "      - LogisticRegression\n",
    "      - LinearDiscriminantAnalysis (LDA)\n",
    "      - QuadraticDiscriminantAnalysis (QDA)\n",
    "    \"\"\"\n",
    "    # Logistic Regression\n",
    "    if isinstance(model, LogisticRegression):\n",
    "        # coef_: shape (n_classes, n_features) or (1, n_features) for binary\n",
    "        # intercept_: shape (n_classes,) or (1,)\n",
    "        total = model.coef_.size + model.intercept_.size\n",
    "        return int(total)\n",
    "\n",
    "    elif isinstance(model, LinearDiscriminantAnalysis):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    # Quadratic Discriminant Analysis\n",
    "    elif isinstance(model, QuadraticDiscriminantAnalysis):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Model of type {type(model)} is not supported.\")\n",
    "\n",
    "        \n",
    "\n",
    "def bic_score(estimator, X, y):\n",
    "    raise NotImplementedError\n",
    "\n",
    "    return bic    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653cc06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_selection(X, y, base_model, max_features=25):    \n",
    "    remaining = set(np.arange(X.shape[1]))\n",
    "    selected, history = [], []\n",
    "    \n",
    "    while remaining:\n",
    "        # try adding each unused feature\n",
    "        bic_candidates = {}\n",
    "        \n",
    "        for feat in remaining:\n",
    "            feats = np.array(selected + [feat])\n",
    "            base_model.fit(X[:, feats], y)\n",
    "            bic = bic_score(base_model, X[:, feats], y) \n",
    "            bic_candidates[feat] = bic\n",
    "\n",
    "        # pick the best feature\n",
    "        feat, bic = None # TODO\n",
    "\n",
    "        if len(selected) < max_features:\n",
    "            selected.append(feat)\n",
    "            remaining.remove(feat)\n",
    "            history.append({\"step\": len(selected),\n",
    "                            \"added_feature\": feat,\n",
    "                            \"bic\": bic})\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return pd.DataFrame(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bbf7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = None #TODO\n",
    "\n",
    "forward_features = forward_selection(X_train_s, y_train, lr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767c860f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(forward_features.step, forward_features.bic)\n",
    "plt.xticks(np.arange(1, 26))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acbf3c3",
   "metadata": {},
   "source": [
    "Q3: what is the optimal number of features according to the forward selection? Use the elbow method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b54b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_n_features = None\n",
    "selected_forward_features = forward_features.added_feature[:forward_n_features] \n",
    "selected_forward_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ef02a5",
   "metadata": {},
   "source": [
    "Q4: write the indexes of the first 4 selected features in oder of importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d83be1f",
   "metadata": {},
   "source": [
    "## Now we perform Lasso regression. \n",
    "\n",
    "Use cross-validation to select the optimal shrinkage parameter based on the accuracy of the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccff9e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def cross_validate_lasso_logistic(X, y, Cs, cv=5, scoring=accuracy_score, random_state=None):\n",
    "    \"\"\"\n",
    "    Perform manual cross-validation to select the optimal L1 regularization parameter C\n",
    "    for a logistic regression model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Feature matrix.\n",
    "    y : array-like, shape (n_samples,)\n",
    "        Target vector.\n",
    "    Cs : list or array of floats\n",
    "        Candidates for the inverse regularization strength (C).\n",
    "    cv : int\n",
    "        Number of cross-validation folds.\n",
    "    scoring : callable\n",
    "        A function with signature scoring(y_true, y_pred) -> float.\n",
    "    random_state : int or None\n",
    "        Seed for reproducibility (passed to StratifiedKFold).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    best_C : float\n",
    "        The value of C that achieved the highest mean cross-validation score.\n",
    "    cv_results : dict\n",
    "        Dictionary with keys:\n",
    "          - 'C': array of candidate Cs\n",
    "          - 'mean_score': array of mean validation scores\n",
    "          - 'std_score': array of std deviations across folds\n",
    "    \"\"\"\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=random_state)\n",
    "    mean_scores = []\n",
    "    std_scores = []\n",
    "\n",
    "    # Loop over candidate Cs\n",
    "    for C in Cs:\n",
    "        fold_scores = []\n",
    "        for train_idx, val_idx in skf.split(X, y):\n",
    "            model = LogisticRegression(\n",
    "                penalty='l1',\n",
    "                C=C,\n",
    "                solver='saga',\n",
    "                max_iter=5000,\n",
    "                random_state=random_state\n",
    "            )\n",
    "            \n",
    "            # TODO: fit model on appropriate shard of data\n",
    "            \n",
    "            # TODO: score the model on appropriate shard of data\n",
    "\n",
    "            score = None # TODO\n",
    "            fold_scores.append(score)\n",
    "\n",
    "        mean_scores.append(np.mean(fold_scores))\n",
    "        std_scores.append(np.std(fold_scores))\n",
    "\n",
    "    mean_scores = np.array(mean_scores)\n",
    "    std_scores  = np.array(std_scores)\n",
    "\n",
    "    best_idx = np.argmax(mean_scores)\n",
    "    best_C   = Cs[best_idx]\n",
    "\n",
    "    cv_results = {\n",
    "        'C': Cs,\n",
    "        'mean_score': mean_scores,\n",
    "        'std_score': std_scores\n",
    "    }\n",
    "\n",
    "    return best_C, cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c4a720",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cs = np.logspace(-4, 4, 20)\n",
    "\n",
    "\n",
    "best_C, results = cross_validate_lasso_logistic(X_train_s, y_train, Cs, cv=5, random_state=42)\n",
    "\n",
    "print(f\"Best C (inverse regularization strength): {best_C:.6f}\")\n",
    "\n",
    "\n",
    "plt.errorbar(results['C'], results['mean_score'], yerr=results['std_score'],\n",
    "             fmt='o-', capsize=5)\n",
    "plt.xscale('log')\n",
    "plt.xlabel('C (inverse regularization strength)')\n",
    "plt.ylabel('Mean validation accuracy')\n",
    "plt.title('Lasso Logistic Regression CV Curve')\n",
    "plt.axvline(best_C, color='red', linestyle='--', label=f'Best C = {best_C:.2e}')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f7f71a",
   "metadata": {},
   "source": [
    "Q5) What is the optimal parameter? Report the value of C found by cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1c43f9",
   "metadata": {},
   "source": [
    "Now we re-fit the model with the C=0.01 see which features have been selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced90d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_lr = None\n",
    "lasso_lr.fit(X_train_s, y_train)\n",
    "lasso_idx = np.where(lasso_lr.coef_[0] != 0)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f2d256",
   "metadata": {},
   "source": [
    "Q6) What is the jaccard similarity between the first 7 features selected via step-wise variable selection and lasso C=0.01?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e50f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard_similarity = None\n",
    "\n",
    "print(f'Jaccard similarity between selected feature sets: {jaccard_similarity:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16083cc",
   "metadata": {},
   "source": [
    "## Now let's fit LDA and QDA\n",
    "\n",
    "Q7) Using step-wise forward feature selections based on the BIC score, what is the optimal number of features for LDA?\n",
    "\n",
    "Q8) What about for QDA?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4f13a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = None\n",
    "forward_features = forward_selection(X_train_s, y_train, lda_model)\n",
    "\n",
    "plt.plot(forward_features.step, forward_features.bic)\n",
    "plt.xticks(np.arange(1, 26))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a0aebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "qda_model = None\n",
    "forward_features = forward_selection(X_train_s, y_train, qda_model)\n",
    "\n",
    "plt.plot(forward_features.step, forward_features.bic)\n",
    "plt.xticks(np.arange(1, 26))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cde9bab",
   "metadata": {},
   "source": [
    "# The multi-class classification problem\n",
    "\n",
    "Now we move to the multi-class classification problem. Use scikit learn to implement the one-vs-rest classification approach based on the Logistic Regression and compare it with the standard softmax link function.\n",
    "\n",
    "For both models, use Cross-Validation to estimate the optimal Lasso shrinkage parameter with K=5. \n",
    "\n",
    "Hint: use LogisticRegressionCV to automatically perform cross validation\n",
    "\n",
    "Report the accuracies on the test sets.\n",
    "\n",
    "#### NB: don't scale the features this time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be1f3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('tcga_150gene.csv')\n",
    "\n",
    "X = data.drop('label', axis=1)\n",
    "y = data['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86651af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "\n",
    "Cs = np.logspace(2, -4, 25)  # search grid (high → low C)\n",
    "\n",
    "ovr_lasso = OneVsRestClassifier() # TODO\n",
    "ovr_lasso.fit(X_train_s, y_train)\n",
    "\n",
    "y_pred_ovr = ovr_lasso.predict(X_test_s)\n",
    "acc_ovr = accuracy_score(y_test, y_pred_ovr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b87a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cs = np.logspace(2, -4, 25)  # search grid (high → low C)\n",
    "\n",
    "multi_lr = None # TODO\n",
    "\n",
    "multi_lr.fit(X_train_s, y_train)\n",
    "\n",
    "y_pred_multi = multi_lr.predict(X_test_s)\n",
    "\n",
    "acc_multi = accuracy_score(y_test, y_pred_multi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
