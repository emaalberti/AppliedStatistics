{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v213oWQNY_4e"
   },
   "source": [
    "**<font size=\"5\">Applied Statistics</font>**\n",
    "\n",
    "<font size=\"3\">MSc in High Performance Computing Engineering, Computer Science and Engineering, Physics Engineering - A.Y. 2024-2025</font>\n",
    "\n",
    "Prof. Mario Beraha - Dott. Vittorio Torri\n",
    "\n",
    "---\n",
    "\n",
    "<font size=\"4\">**Lab 5 - Linear and Quadratic Discriminant Analysis, K-nearest neighbours**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A25mZ6wlfdDd"
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6lQyucZOedIO"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import shapiro, bartlett, f_oneway, norm\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5LAHsf-I2IV9"
   },
   "source": [
    "# Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vaMGahkG2LU1"
   },
   "source": [
    "## Univariate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sbDWvtIumiqd"
   },
   "source": [
    "Interferon-gamma (IFN-gamma) and interleukin-5 (IL-5) are multifunctional cytokines that regulate immune responses, cell proliferation, and tumour development and progression, which frequently have functionally opposing roles.\n",
    "\n",
    "Idea: we aim to find a \"rule\" to classify patients as Group A (the treatment has effect) or Group B (the treatment has no effect)  given the measurements of Inf-g (Interferon gamma) and IL-5 (Interleukin 5).\n",
    "For this example, we discard the IL-5 variable (which seems to have poor\n",
    "\"discriminative power\") and we consider the univariate case with Inf-g only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P9GSEWqb4v8d"
   },
   "source": [
    "### Load and check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1749562541445,
     "user": {
      "displayName": "Emanuele Alberti",
      "userId": "01048477993232507094"
     },
     "user_tz": -120
    },
    "id": "7pDBbJEp2HD3",
    "outputId": "04eee429-01c0-4a23-9484-5e04b9360de3"
   },
   "outputs": [],
   "source": [
    "cyto = pd.read_csv(\"../DatasetsLabs/cytokines.txt\", sep=\" \")\n",
    "\n",
    "print(cyto)\n",
    "\n",
    "# We separate groups A and B:\n",
    "A_idx = cyto.index[ cyto[\"group\"] == 'A' ]\n",
    "B_idx = cyto.index[ cyto[\"group\"] == 'B' ]\n",
    "\n",
    "Infg = cyto[\"Infg\"].values\n",
    "IL5  = cyto[\"IL5\"].values\n",
    "groups = cyto[\"group\"].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 217,
     "status": "ok",
     "timestamp": 1749562541662,
     "user": {
      "displayName": "Emanuele Alberti",
      "userId": "01048477993232507094"
     },
     "user_tz": -120
    },
    "id": "vof0UzyI3fau",
    "outputId": "b884c04d-9818-476f-f5b1-604f21466887"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "# Blue for A, Red for B\n",
    "plt.scatter(Infg[A_idx], IL5[A_idx], color='blue', label='A', marker='o')\n",
    "plt.scatter(Infg[B_idx], IL5[B_idx], color='red',  label='B', marker='o')\n",
    "plt.xlabel(\"Inf-g\")\n",
    "plt.ylabel(\"IL-5\")\n",
    "plt.legend()\n",
    "plt.title(\"Cytokines data\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1749562541674,
     "user": {
      "displayName": "Emanuele Alberti",
      "userId": "01048477993232507094"
     },
     "user_tz": -120
    },
    "id": "TEKbzqVV4iPz",
    "outputId": "dfb3e0c8-0975-4500-e64e-635c0f34ed43"
   },
   "outputs": [],
   "source": [
    "# Shapiro test for normality of A and B\n",
    "stat_A, pval_A = shapiro(Infg[A_idx])\n",
    "stat_B, pval_B = shapiro(Infg[B_idx])\n",
    "print(\"Shapiro test group A:\", stat_A, pval_A)\n",
    "print(\"Shapiro test group B:\", stat_B, pval_B)\n",
    "\n",
    "# Bartlett test for equality of variance\n",
    "bart_stat, bart_pval = bartlett(Infg[A_idx], Infg[B_idx])\n",
    "print(\"Bartlett test: statistic =\", bart_stat, \"p-value =\", bart_pval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ujmSIXLB40Sd"
   },
   "source": [
    "### Manual implementation of LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1749562541706,
     "user": {
      "displayName": "Emanuele Alberti",
      "userId": "01048477993232507094"
     },
     "user_tz": -120
    },
    "id": "D-Kg-qK84pfb",
    "outputId": "255afe78-406d-4386-ac03-2fcb3520875c"
   },
   "outputs": [],
   "source": [
    "nA = len(A_idx)\n",
    "nB = len(B_idx)\n",
    "n  = nA + nB\n",
    "\n",
    "PA = nA / n\n",
    "PB = nB / n\n",
    "\n",
    "MA = np.mean(Infg[A_idx])\n",
    "MB = np.mean(Infg[B_idx])\n",
    "\n",
    "SA = np.var(Infg[A_idx], ddof=1)\n",
    "SB = np.var(Infg[B_idx], ddof=1)\n",
    "\n",
    "# Pooled variance estimate\n",
    "S  = ((nA - 1) * SA + (nB - 1) * SB) / (n - 2)\n",
    "\n",
    "print(f\"Means: M_A={MA:.3f}, M_B={MB:.3f}\")\n",
    "print(f\"Pooled var: S={S:.3f}\")\n",
    "print(f\"Group prior probabilities: P(A)={PA}, P(B)={PB}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DyCF2zRRojaj"
   },
   "source": [
    "$$ P(y_i|X) = \\frac{P(X|y_i)P(y_i)}{P(X)} = \\frac{P(X|y_i)P(y_i)}{\\sum_{j}P(X|y_j)P(y_j)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 619,
     "status": "ok",
     "timestamp": 1749562542326,
     "user": {
      "displayName": "Emanuele Alberti",
      "userId": "01048477993232507094"
     },
     "user_tz": -120
    },
    "id": "ADW2RB5a49Lv",
    "outputId": "0a4459fa-9bcc-432a-be48-8633a61f33d7"
   },
   "outputs": [],
   "source": [
    "xgrid = np.linspace(-10, 35, 200)\n",
    "\n",
    "# pdf for group A\n",
    "pdfA = norm.pdf(xgrid, loc=MA, scale=np.sqrt(S))\n",
    "# pdf for group B\n",
    "pdfB = norm.pdf(xgrid, loc=MB, scale=np.sqrt(S))\n",
    "\n",
    "plt.figure(figsize=(7,8))\n",
    "\n",
    "# Top plot: PA * fA(x) and PB * fB(x)\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(xgrid, PA*pdfA, color='blue', label=r'$P(A)f_A(x)$')\n",
    "plt.plot(xgrid, PB*pdfB, color='red',  label=r'$P(B)f_B(x)$')\n",
    "plt.scatter(Infg[A_idx], np.zeros(nA), color='blue', s=30)\n",
    "plt.scatter(Infg[B_idx], np.zeros(nB), color='red',  s=30)\n",
    "plt.ylim(0, None)\n",
    "plt.title(\"LDA - Weighted PDFs\")\n",
    "plt.legend()\n",
    "\n",
    "# Bottom plot: Posterior probabilities\n",
    "postA = PA*pdfA / (PA*pdfA + PB*pdfB)\n",
    "postB = PB*pdfB / (PA*pdfA + PB*pdfB)\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(xgrid, postA, color='blue', label='P(A|x)')\n",
    "plt.plot(xgrid, postB, color='red',  label='P(B|x)')\n",
    "plt.scatter(Infg[A_idx], np.zeros(nA), color='blue', s=30)\n",
    "plt.scatter(Infg[B_idx], np.zeros(nB), color='red',  s=30)\n",
    "plt.ylim(0,1)\n",
    "plt.title(\"LDA - Posterior probabilities\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N44_F_gyqifi"
   },
   "source": [
    "### LDA via scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 227,
     "status": "ok",
     "timestamp": 1749562542555,
     "user": {
      "displayName": "Emanuele Alberti",
      "userId": "01048477993232507094"
     },
     "user_tz": -120
    },
    "id": "J63mg5v1qkKg",
    "outputId": "cfe47a28-74f5-4d96-c1c3-134c2403b383"
   },
   "outputs": [],
   "source": [
    "X = Infg.reshape(-1, 1)\n",
    "y = groups\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X, y)\n",
    "\n",
    "# Posterior probability for x=0:\n",
    "x0_val = 0.0\n",
    "posterior0 = lda.predict_proba([[x0_val]])[0]\n",
    "postA_x0, postB_x0 = posterior0  # two classes (A, B)\n",
    "print(\"Posterior at x=0:\", posterior0)\n",
    "print(\"Class assigned at x=0:\", lda.predict([[x0_val]]))\n",
    "\n",
    "# Posterior for a grid of x\n",
    "xgrid = np.linspace(-10, 35, 200).reshape(-1, 1)\n",
    "post_grid = lda.predict_proba(xgrid)  # columns: prob of A, prob of B\n",
    "postA_skl = post_grid[:,0]\n",
    "postB_skl = post_grid[:,1]\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(xgrid, postA, color='blue', label='P(A|x)')\n",
    "plt.plot(xgrid, postB, color='red',  label='P(B|x)')\n",
    "plt.plot(xgrid, postA_skl, '--', color='lightblue', label='P(A|x) skl')\n",
    "plt.plot(xgrid, postB_skl, '--', color='darkred',  label='P(B|x) skl')\n",
    "plt.scatter(Infg[A_idx], np.zeros(nA), color='blue', s=30)\n",
    "plt.scatter(Infg[B_idx], np.zeros(nB), color='red',  s=30)\n",
    "# Highlight the value at x=0:\n",
    "plt.axvline(x=x0_val, color='gray', linestyle='--')\n",
    "# 2. Markers for the two posterior values at x=0\n",
    "plt.scatter([x0_val], [postA_x0], s=80, color='blue',  marker='*', zorder=5,\n",
    "            label='P(A|x=0) = {:.3f}'.format(postA_x0))\n",
    "plt.scatter([x0_val], [postB_x0], s=80, color='red',   marker='*', zorder=5,\n",
    "            label='P(B|x=0) = {:.3f}'.format(postB_x0))\n",
    "plt.ylim(0,1)\n",
    "plt.title(\"LDA - Posterior probabilities\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQHTUU7gt6fV"
   },
   "source": [
    "Explicitly set the priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 262,
     "status": "ok",
     "timestamp": 1749562542818,
     "user": {
      "displayName": "Emanuele Alberti",
      "userId": "01048477993232507094"
     },
     "user_tz": -120
    },
    "id": "O_yU4FOKqnXO",
    "outputId": "564d8cfa-dd5d-40c0-fbff-0fd67bffac82"
   },
   "outputs": [],
   "source": [
    "lda_1 = LinearDiscriminantAnalysis(priors=[0.95, 0.05])\n",
    "lda_1.fit(X, y)\n",
    "\n",
    "# Posterior on the same grid:\n",
    "post_grid_1 = lda_1.predict_proba(xgrid)\n",
    "postA_1 = post_grid_1[:, 0]\n",
    "postB_1 = post_grid_1[:, 1]\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "\n",
    "plt.plot(xgrid, postA_1, color='blue', label='P(A|x) [priors=0.95,0.05]')\n",
    "plt.plot(xgrid, postB_1, color='red',  label='P(B|x) [priors=0.95,0.05]')\n",
    "\n",
    "plt.plot(xgrid, postA_skl, '--', color='gray', label='P(A|x) [old LDA]')\n",
    "plt.plot(xgrid, postB_skl, '--', color='darkgray', label='P(B|x) [old LDA]')\n",
    "\n",
    "# Add horizontal line at 0.5\n",
    "plt.axhline(y=0.5, color='black', linestyle=':')\n",
    "\n",
    "# Add the points on x-axis for groups A and B\n",
    "plt.scatter(Infg[A_idx], np.zeros(len(A_idx)), color='blue',  s=30)\n",
    "plt.scatter(Infg[B_idx], np.zeros(len(B_idx)), color='red',   s=30)\n",
    "\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel(\"x (Infg)\")\n",
    "plt.ylabel(\"Posterior Probability\")\n",
    "plt.title(\"Compare LDA Posteriors (old vs new priors)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BuigIhU6uTzR"
   },
   "source": [
    "## Multivariate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CFiunjnTuZS9"
   },
   "source": [
    "### Iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oyqX7pdDuag5"
   },
   "source": [
    "Considering only the first two variables of the iris datasets (Sepal Length and Sepal Width)\n",
    "\n",
    "p = 2 # num variables\n",
    "\n",
    "g = 3 # num groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 628,
     "status": "ok",
     "timestamp": 1749562543448,
     "user": {
      "displayName": "Emanuele Alberti",
      "userId": "01048477993232507094"
     },
     "user_tz": -120
    },
    "id": "wZsoNiWQuJ41",
    "outputId": "57b776f8-79cb-4ad6-a68f-427f30a1c4a7"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "iris_data = load_iris()\n",
    "X_iris = iris_data.data[:, :2]  # only Sepal.Length, Sepal.Width\n",
    "y_iris = iris_data.target       # 0, 1, 2 for setosa, versicolor, virginica\n",
    "species_names = iris_data.target_names\n",
    "\n",
    "# We'll add small jitter\n",
    "rng = np.random.RandomState(1)\n",
    "X_iris = X_iris + rng.normal(scale=0.025, size=X_iris.shape)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(X_iris[:,0], X_iris[:,1], c=y_iris, cmap='brg', s=30)\n",
    "\n",
    "handles = [\n",
    "    mpatches.Patch(color=plt.get_cmap(\"brg\",3)(0), label='Setosa'),\n",
    "    mpatches.Patch(color=plt.get_cmap(\"brg\",3)(1), label='Versicolor'),\n",
    "    mpatches.Patch(color=plt.get_cmap(\"brg\",3)(2), label='Virginica')\n",
    "]\n",
    "plt.legend(handles=handles, loc='upper right')\n",
    "\n",
    "plt.title(\"Iris Sepal\")\n",
    "plt.xlabel(\"Sepal.Length\")\n",
    "plt.ylabel(\"Sepal.Width\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1749562543456,
     "user": {
      "displayName": "Emanuele Alberti",
      "userId": "01048477993232507094"
     },
     "user_tz": -120
    },
    "id": "1ecZ97SO0GhO",
    "outputId": "225e8454-08aa-4a84-a2c3-8646158a6417"
   },
   "outputs": [],
   "source": [
    "lda_iris = LinearDiscriminantAnalysis()\n",
    "lda_iris.fit(X_iris, y_iris)\n",
    "\n",
    "print(\"Coefficients of linear discriminants:\\n\", lda_iris.coef_)\n",
    "print(\"Intercepts:\\n\", lda_iris.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1749562543467,
     "user": {
      "displayName": "Emanuele Alberti",
      "userId": "01048477993232507094"
     },
     "user_tz": -120
    },
    "id": "QRNum_LsIdIn",
    "outputId": "2d7d0c1b-4555-4699-8410-8fa634318d15"
   },
   "outputs": [],
   "source": [
    "y_pred = lda_iris.predict(X_iris)\n",
    "conf_mat = confusion_matrix(y_iris, y_pred)\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 179,
     "status": "ok",
     "timestamp": 1749562543659,
     "user": {
      "displayName": "Emanuele Alberti",
      "userId": "01048477993232507094"
     },
     "user_tz": -120
    },
    "id": "50xxefHoIkJ_",
    "outputId": "f9f9b431-037c-47d8-bd7d-3e2e2a22a23b"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_mat, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=species_names, yticklabels=species_names)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix - Iris LDA\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1749562543698,
     "user": {
      "displayName": "Emanuele Alberti",
      "userId": "01048477993232507094"
     },
     "user_tz": -120
    },
    "id": "Et7q1bHnIeZx",
    "outputId": "8b77a386-5883-4a83-e090-7b8eb4185791"
   },
   "outputs": [],
   "source": [
    "# APER (apparent error rate - proportion of misclassified samples)\n",
    "# NB: this formula is correct if the proportions are estimated via empirical frequencies\n",
    "# Otherwise it is sum of P(error|group g) * P(group g) = sum{ # errors_for_group_g * prior_prob[g]}\n",
    "n_samples = len(y_iris)\n",
    "misclassified = (y_pred != y_iris).sum()\n",
    "APER = misclassified / n_samples\n",
    "print(\"APER =\", APER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1749562543701,
     "user": {
      "displayName": "Emanuele Alberti",
      "userId": "01048477993232507094"
     },
     "user_tz": -120
    },
    "id": "JxrTV0k6JJRi",
    "outputId": "6576ca93-6fba-44ce-91ee-d50bcd9d5b09"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_iris, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xHJ4qZlSwWNk"
   },
   "source": [
    "Let's plot the decision boundary identified by LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 257,
     "status": "ok",
     "timestamp": 1749562543959,
     "user": {
      "displayName": "Emanuele Alberti",
      "userId": "01048477993232507094"
     },
     "user_tz": -120
    },
    "id": "GsMsWmaivlmJ",
    "outputId": "c978c00e-c661-43eb-87e2-728e0efd3116"
   },
   "outputs": [],
   "source": [
    "def plot_lda_partition(model, X, y, class_labels=None, title=\"LDA Partition\", xtitle=\"Sepal.Length\", ytitle=\"Sepal.Width\"):\n",
    "  x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "  y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "  xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200),\n",
    "                        np.linspace(y_min, y_max, 200))\n",
    "  grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "  unique_classes = np.unique(y)\n",
    "  n_classes = len(unique_classes)\n",
    "  cmap = plt.get_cmap(\"brg\", n_classes)\n",
    "\n",
    "  class_pred = model.predict(grid_points)\n",
    "\n",
    "  plt.figure()\n",
    "  plt.scatter(X[:,0], X[:,1], c=y, cmap='brg', s=30)\n",
    "  plt.title(\"Iris LDA Partition\")\n",
    "  # Now let's draw boundaries where the predicted class changes:\n",
    "  class_pred_matrix = class_pred.reshape(xx.shape)\n",
    "  # We'll plot the contour lines between classes:\n",
    "  # e.g., any place that transitions from class i to j is a boundary.\n",
    "  plt.contour(xx, yy, class_pred_matrix,\n",
    "              colors='k', linestyles='--')\n",
    "\n",
    "  # Mark class means (model.means_ shape: [n_classes, n_features])\n",
    "  means = model.means_\n",
    "  plt.scatter(means[:,0], means[:,1], marker='x',\n",
    "              c=range(len(means)), cmap='brg', s=100, linewidths=2)\n",
    "\n",
    "  if class_labels is None:\n",
    "      class_labels = [f\"Class {cls}\" for cls in unique_classes]  # Default labels if not provided\n",
    "\n",
    "  handles = [mpatches.Patch(color=cmap(i), label=class_labels[i]) for i in range(n_classes)]\n",
    "  plt.legend(handles=handles, loc='upper right')\n",
    "\n",
    "  plt.xlabel(xtitle)\n",
    "  plt.ylabel(ytitle)\n",
    "  plt.show()\n",
    "\n",
    "plot_lda_partition(lda_iris, X_iris, y_iris, class_labels=species_names, title=\"Iris LDA Partition\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GoEA_Uf9BqSi"
   },
   "source": [
    "# Quadratic Discriminant Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "01Wpy5jYCYV-"
   },
   "source": [
    "## Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V_zT1nqEv-mt"
   },
   "outputs": [],
   "source": [
    "# fit a Quadratic Discriminant Analysis model from scikit learn, compute the APER and the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1749562543978,
     "user": {
      "displayName": "Emanuele Alberti",
      "userId": "01048477993232507094"
     },
     "user_tz": -120
    },
    "id": "yZ87TQpu291Q",
    "outputId": "a529fcc3-98ad-4d2e-ddbf-38b6182236f3"
   },
   "outputs": [],
   "source": [
    "qda_iris = QuadraticDiscriminantAnalysis()\n",
    "qda_iris.fit(X_iris, y_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1749562543983,
     "user": {
      "displayName": "Emanuele Alberti",
      "userId": "01048477993232507094"
     },
     "user_tz": -120
    },
    "id": "PQeZAlKd3BC6",
    "outputId": "5e0069b9-78b9-429e-b3e5-d2a5818bd491"
   },
   "outputs": [],
   "source": [
    "y_pred_qda = qda_iris.predict(X_iris)\n",
    "conf_mat_qda = pd.crosstab(pd.Series(y_iris, name='True'),\n",
    "                           pd.Series(y_pred_qda, name='Predicted'))\n",
    "print(conf_mat_qda)\n",
    "\n",
    "APER_q = (y_pred_qda != y_iris).sum() / len(y_iris)\n",
    "print(\"APER QDA =\", APER_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 282,
     "status": "ok",
     "timestamp": 1749562544276,
     "user": {
      "displayName": "Emanuele Alberti",
      "userId": "01048477993232507094"
     },
     "user_tz": -120
    },
    "id": "kpsnGbHbp7IA",
    "outputId": "95e491e2-250f-43be-be0a-068d4ee4721e"
   },
   "outputs": [],
   "source": [
    "def plot_qda_partition(model, X, y, class_labels=None, title=\"QDA Partition\", cmap=None, xtitle=\"Sepal.Length\", ytitle=\"Sepal.Width\"):\n",
    "    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200),\n",
    "                         np.linspace(y_min, y_max, 200))\n",
    "    grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "    class_pred = model.predict(grid_points)\n",
    "    if isinstance(class_pred[0], str):\n",
    "      class_pred = np.array([np.where(class_labels == i) for i in class_pred])\n",
    "    class_pred_matrix = class_pred.reshape(xx.shape)\n",
    "\n",
    "    unique_classes = np.unique(y)\n",
    "    n_classes = len(unique_classes)\n",
    "\n",
    "    cmap = plt.get_cmap(\"brg\", n_classes)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(X[:,0], X[:,1], c=y, cmap=cmap, s=30)\n",
    "    plt.title(title)\n",
    "    plt.contour(xx, yy, class_pred_matrix,\n",
    "                colors='k', linestyles='--')\n",
    "\n",
    "    # Mark class means\n",
    "    means = model.means_\n",
    "    plt.scatter(means[:,0], means[:,1], marker='x',\n",
    "                c=range(len(means)), cmap=cmap, s=100, linewidths=2)\n",
    "\n",
    "    if class_labels is None:\n",
    "        class_labels = [f\"Class {cls}\" for cls in unique_classes]  # Default labels if not provided\n",
    "\n",
    "    handles = [mpatches.Patch(color=cmap(i), label=class_labels[i]) for i in range(n_classes)]\n",
    "    plt.legend(handles=handles, loc='upper right')\n",
    "\n",
    "    plt.xlabel(xtitle)\n",
    "    plt.ylabel(ytitle)\n",
    "    plt.show()\n",
    "\n",
    "plot_qda_partition(qda_iris, X_iris, y_iris, class_labels=species_names, title=\"Iris QDA Partition\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7YFgwPhbCuoT"
   },
   "source": [
    "## Cost-sensitive classification (Banknotes example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QdkYGiD-DLNO"
   },
   "source": [
    "The vending machines of the Exxon fuel contain optical detectors able\n",
    "to measure the size of the banknotes inserted. Knowing that 0.1% of the\n",
    "10\\$ banknotes in circulation are counterfeit, Exxon would like to implement a\n",
    "software to identify false 10$ banknotes, as to minimize the economic losses.\n",
    "Assuming that:\n",
    "  - both the populations of real and false banknotes follow a normal distribution (with different mean and covariance matrices);\n",
    "  \n",
    "  - accepting a false banknote leads to an economic loss of 10$;\n",
    "\n",
    "  - rejecting a true banknote brings a economic loss quantifiable in 5 cents;\n",
    "\n",
    " satisfy the following requests of the Exxon:\n",
    "\n",
    " a) build an appropriate classifier, estimating the unknown parameters starting from the two datasets moneytrue.txt and moneyfalse.txt, containing data about 100 true banknotes and 100 counterfeit banknotes (in mm). Qualitatively show the two classification regions in a graph;\n",
    "\n",
    " b) calculate the APER of the classifier and, based on the APER, estimate the expected economic damage of the classifier;\n",
    "\n",
    " c) what is the estimated probability that the first 10$ banknote inserted in the machine is rejected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 925,
     "status": "ok",
     "timestamp": 1749562545200,
     "user": {
      "displayName": "Emanuele Alberti",
      "userId": "01048477993232507094"
     },
     "user_tz": -120
    },
    "id": "LocZyrSaw26U",
    "outputId": "d4ee9092-3e29-4bd9-9c44-a75290f52e94"
   },
   "outputs": [],
   "source": [
    "true_df  = pd.read_table(\"../DatasetsLabs/moneytrue.txt\", sep=\" \")   # columns e.g. V1, V2\n",
    "false_df = pd.read_table(\"../DatasetsLabs/moneyfalse.txt\", sep=\" \")  # columns e.g. V1, V2\n",
    "\n",
    "true_data  = true_df[[\"V1\",\"V2\"]].values\n",
    "false_data = false_df[[\"V1\",\"V2\"]].values\n",
    "\n",
    "banknotes = np.vstack([true_data, false_data])\n",
    "vf = np.array([\"true\"]*len(true_data) + [\"false\"]*len(false_data), dtype=object)\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.scatter(true_data[:,0],  true_data[:,1], color=(0.0, 0.0, 1.0, 1.0),  label='true', s=20)\n",
    "plt.scatter(false_data[:,0], false_data[:,1], color=(0.0, 1.0, 0.0, 1.0), label='false', s=20)\n",
    "plt.xlabel(\"V1\")\n",
    "plt.ylabel(\"V2\")\n",
    "plt.title(\"Banknotes\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ni8ccDs3HNdL"
   },
   "source": [
    "Priori probabilities determine the importance of a class. If misclassifying False as True is very costly, we need to increase the prior probability of False:\n",
    "\n",
    "$$\n",
    "\\pi_{False}' = \\frac{c_{TF}\\cdot\\pi_{False}}{c_{TF}\\cdot\\pi_{False} + c_{FT}\\cdot\\pi_{True}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EFah0eQ8SVQf"
   },
   "source": [
    " a) build an appropriate classifier, estimating the unknown parameters starting from the two datasets moneytrue.txt and moneyfalse.txt, containing data about 100 true banknotes and 100 counterfeit banknotes (in mm). Qualitatively show the two classification regions in a graph;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 378,
     "status": "ok",
     "timestamp": 1749562545579,
     "user": {
      "displayName": "Emanuele Alberti",
      "userId": "01048477993232507094"
     },
     "user_tz": -120
    },
    "id": "D3jt4y9rC-kW",
    "outputId": "6fad04b4-72f9-4fa7-d1b0-7fb5d6821ace"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "c_tf = 10    # cost of accepting a false banknote\n",
    "c_ft = 0.05  # cost of rejecting a true banknote\n",
    "pf   = 0.001\n",
    "pt   = 1 - pf\n",
    "\n",
    "# Adjusted priors:\n",
    "den = c_tf*pf + c_ft*pt # normalization factor to keep them sum to 1\n",
    "p_true_c = pt*c_ft / den\n",
    "p_false_c = pf*c_tf / den\n",
    "prior_c = [p_true_c, p_false_c]\n",
    "\n",
    "desired_order = [\"true\", \"false\"]  # the order MUST be consisted with the order of the priors!\n",
    "y_encoded = np.array([desired_order.index(label) for label in vf])\n",
    "\n",
    "qda_bank = QuadraticDiscriminantAnalysis(priors=prior_c)\n",
    "qda_bank.fit(banknotes, y_encoded)\n",
    "\n",
    "lda_bank = LinearDiscriminantAnalysis(priors=prior_c)\n",
    "lda_bank.fit(banknotes, y_encoded)\n",
    "\n",
    "\n",
    "plot_qda_partition(qda_bank, banknotes, y_encoded, class_labels=desired_order, title=\"Banknotes QDA Partition\", xtitle=\"V1\", ytitle=\"V2\")\n",
    "plot_lda_partition(lda_bank, banknotes, y_encoded, class_labels=desired_order, title=\"Banknotes LDA Partition\", xtitle=\"V1\", ytitle=\"V2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QLByeEKAsgn1"
   },
   "source": [
    "b) calculate the APER of the classifier and, based on the APER, estimate the expected economic damage of the classifier;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1749562545584,
     "user": {
      "displayName": "Emanuele Alberti",
      "userId": "01048477993232507094"
     },
     "user_tz": -120
    },
    "id": "jbVtUN3WsG1Q",
    "outputId": "781d1fd3-7e88-4f2d-cdde-836614254cf6"
   },
   "outputs": [],
   "source": [
    "y_pred = qda_bank.predict(banknotes)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(y_encoded, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "tp, fn, fp, tn = conf_matrix.ravel()  # Extract False Positives (FP) and False Negatives (FN)\n",
    "\n",
    "## NB: be aware that here we have the TRUE as the first class, but it is more common to have viceversa\n",
    "\n",
    "# APER Calculation using extracted FP and FN values\n",
    "# APER = P(true) * P(misclassified | true) + P(false) * P(misclassified | false)\n",
    "aper = p_true_c * (fn / (tp + fn)) + p_false_c * (fp / (fp + tn))\n",
    "\n",
    "print(\"\\nApparent Error Rate (APER): {:.4f}\".format(aper))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SwhL2L4ktMPJ"
   },
   "source": [
    "c) what is the estimated probability that the first 10$ banknote inserted in the machine is rejected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1749562545592,
     "user": {
      "displayName": "Emanuele Alberti",
      "userId": "01048477993232507094"
     },
     "user_tz": -120
    },
    "id": "ff1Enj3FtO_t",
    "outputId": "fc865ae9-a8eb-4675-bbff-79003598917a"
   },
   "outputs": [],
   "source": [
    "# P[rejected] = P[rejected | true]P[true] + P[rejected | false]P[false]\n",
    "\n",
    "(fn / (fn+ tp)) * pt + (tn / (tn + fp)) * pf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qpvJ8UFAS8LA"
   },
   "source": [
    "# Fisher Discriminant Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zX77ualpp6Nh"
   },
   "source": [
    "LDA can also be used to project the data into a lower dimensional space, which maximizes the separability between the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1749565793833,
     "user": {
      "displayName": "Emanuele Alberti",
      "userId": "01048477993232507094"
     },
     "user_tz": -120
    },
    "id": "uosBH1AXS_Yd",
    "outputId": "51bc6bfa-7ba0-48e5-9376-a145cfbf75a2"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "iris_data = load_iris()\n",
    "X_iris = iris_data.data\n",
    "X_iris.shape\n",
    "X = X_iris\n",
    "y = y_iris\n",
    "\n",
    "# Apply Fisher's Linear Discriminant Analysis (LDA)\n",
    "lda = LinearDiscriminantAnalysis(n_components=2)\n",
    "X_lda = lda.fit_transform(X, y)  # Transform data into canonical coordinates\n",
    "\n",
    "X_lda.shape, X_iris.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1749565795227,
     "user": {
      "displayName": "Emanuele Alberti",
      "userId": "01048477993232507094"
     },
     "user_tz": -120
    },
    "id": "TdXl1179Fi7e",
    "outputId": "17062316-0208-462b-8118-7372648379f4"
   },
   "outputs": [],
   "source": [
    "# Compute the confusion matrix for model performance\n",
    "y_pred = lda.predict(X)\n",
    "conf_matrix = confusion_matrix(y, y_pred)\n",
    "APER = 1 - np.trace(conf_matrix) / np.sum(conf_matrix)\n",
    "\n",
    "print(\"Misclassification Rate (APER):\", APER)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433
    },
    "executionInfo": {
     "elapsed": 553,
     "status": "ok",
     "timestamp": 1749565676656,
     "user": {
      "displayName": "Emanuele Alberti",
      "userId": "01048477993232507094"
     },
     "user_tz": -120
    },
    "id": "ybDubfwkLOJe",
    "outputId": "ca16eede-f10c-4510-fd1e-1e7d834b9ba9"
   },
   "outputs": [],
   "source": [
    "#applying fisher\n",
    "plt.scatter(X_iris[:, 0], X_iris[:, 1])\n",
    "X_iris_new = X_iris[0:, :2]\n",
    "fisher = LinearDiscriminantAnalysis(n_components=2)\n",
    "fisher.fit(X_iris_new, y_iris)\n",
    "X_new = fisher.transform(X_iris_new)\n",
    "#plt.scatter(X_new[:,0], X_new[:,1], c='red')\n",
    "\n",
    "predictions=fisher.predict(X_iris_new)\n",
    "predictions\n",
    "\n",
    "color_species = ['red', 'green', 'blue']\n",
    "\n",
    "for i, color in zip(range(3), color_species):\n",
    "    plt.scatter(X_iris_new[y == i, 0], X_iris_new[y == i, 1], c=color, alpha=0.6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0TyKvmt3yR97"
   },
   "source": [
    "How to classify a new observation in [5.85, 2.90]?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 505
    },
    "executionInfo": {
     "elapsed": 612,
     "status": "ok",
     "timestamp": 1749562546229,
     "user": {
      "displayName": "Emanuele Alberti",
      "userId": "01048477993232507094"
     },
     "user_tz": -120
    },
    "id": "gRpoxjbuqikt",
    "outputId": "54685bc1-24e5-4495-a52b-a1c2d5bef623"
   },
   "outputs": [],
   "source": [
    "x_new = np.array([[5.85, 2.90]])  # New observation\n",
    "cc_new = fisher.transform(x_new)  # Project into Fisherâ€™s space\n",
    "assigned_class = fisher.predict(x_new)\n",
    "print(\"New observation classified as:\", species_names[assigned_class[0]])\n",
    "\n",
    "color_species = ['red', 'green', 'blue']\n",
    "\n",
    "# Compute class means in LDA space\n",
    "class_means_lda = lda.transform(lda.means_)  # Get means in LDA space\n",
    "\n",
    "# Plot LDA Results with Connection Lines to Class Centers\n",
    "def plot_fisher_score_with_connections():\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    # Original Coordinate Space\n",
    "    for i, color in zip(range(3), color_species):\n",
    "        ax[0].scatter(X[y == i, 0], X[y == i, 1], c=color, label=species_names[i], alpha=0.6)\n",
    "\n",
    "    ax[0].scatter(x_new[0, 0], x_new[0, 1], c='gold', marker='X', s=100, label=\"New Point\")\n",
    "    ax[0].set_xlabel(\"Sepal Length\")\n",
    "    ax[0].set_ylabel(\"Sepal Width\")\n",
    "    ax[0].set_title(\"Original Feature Space\")\n",
    "    ax[0].legend()\n",
    "\n",
    "    # Canonical Coordinate Space (LDA Projection)\n",
    "    for i, color in zip(range(3), color_species):\n",
    "        ax[1].scatter(X_lda[y == i, 0], X_lda[y == i, 1], c=color, label=species_names[i], alpha=0.6)\n",
    "\n",
    "    ax[1].scatter(cc_new[0, 0], cc_new[0, 1], c='gold', marker='X', s=100, label=\"New Point\")\n",
    "\n",
    "    # Connect new observation to class means\n",
    "    for mean, color in zip(class_means_lda, color_species):\n",
    "        ax[1].scatter(mean[0], mean[1], c=color, marker=\"X\", s=100, edgecolors=\"black\", label=f\"Mean {color}\")\n",
    "        ax[1].plot([cc_new[0, 0], mean[0]], [cc_new[0, 1], mean[1]], color=color, linestyle=\"dashed\")\n",
    "\n",
    "    ax[1].set_xlabel(\"First Canonical Coordinate\")\n",
    "    ax[1].set_ylabel(\"Second Canonical Coordinate\")\n",
    "    ax[1].set_title(\"Canonical Coordinates (LDA Projection)\")\n",
    "    ax[1].legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_fisher_score_with_connections()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "executionInfo": {
     "elapsed": 357,
     "status": "ok",
     "timestamp": 1749562546584,
     "user": {
      "displayName": "Emanuele Alberti",
      "userId": "01048477993232507094"
     },
     "user_tz": -120
    },
    "id": "jYyvd1xJyZUp",
    "outputId": "4591789c-c6dc-41ab-d4eb-fe54aa03dc14"
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200),\n",
    "                      np.linspace(y_min, y_max, 200))\n",
    "\n",
    "# Predict on the grid\n",
    "Z = fisher.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.contourf(xx, yy, Z, alpha=0.3, cmap=ListedColormap(color_species))\n",
    "\n",
    "for i, color in zip(range(3), color_species):\n",
    "    plt.scatter(X[y == i, 0], X[y == i, 1], c=color, label=species_names[i], edgecolors='k')\n",
    "\n",
    "plt.scatter(x_new[0, 0], x_new[0, 1], c='gold', marker='X', s=100, label=\"New Point\", edgecolors='black')\n",
    "plt.xlabel(\"Sepal Length\")\n",
    "plt.ylabel(\"Sepal Width\")\n",
    "plt.title(\"LDA Decision Boundaries\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "executionInfo": {
     "elapsed": 403,
     "status": "ok",
     "timestamp": 1749565802408,
     "user": {
      "displayName": "Emanuele Alberti",
      "userId": "01048477993232507094"
     },
     "user_tz": -120
    },
    "id": "Q_VMxhUgEslZ",
    "outputId": "91d0dbd4-8e7a-4855-e978-87b59d40d510"
   },
   "outputs": [],
   "source": [
    "X_lda = lda.fit_transform(X_iris, y_iris)  # Canonical coordinates of data\n",
    "\n",
    "# Fisher directions (discriminant vectors)\n",
    "a1, a2 = lda.scalings_[:, 0], lda.scalings_[:, 1]\n",
    "\n",
    "# Normalize Fisher directions for visualization\n",
    "a1 /= np.linalg.norm(a1)\n",
    "a2 /= np.linalg.norm(a2)\n",
    "\n",
    "# Compute projections onto Fisher directions in the original space\n",
    "proj_a1 = np.outer(X_iris @ a1, a1) / np.sum(a1 ** 2)\n",
    "proj_a2 = np.outer(X_iris @ a2, a2) / np.sum(a2 ** 2)\n",
    "\n",
    "class_means = lda.means_  # Means in original space\n",
    "\n",
    "color_species = np.array(color_species)\n",
    "\n",
    "# Plot: Projection on Canonical Directions (Original Space)**\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(X_iris[:, 0], X_iris[:, 1], c=color_species[y], alpha=0.5, label=\"Data\")\n",
    "plt.scatter(class_means[:, 0], class_means[:, 1], c=color_species, marker=\"X\", s=100, edgecolors=\"black\", label=\"Class Means\")\n",
    "\n",
    "# Scale factor for better visibility\n",
    "t = 5\n",
    "\n",
    "# Arrows for Fisher directions\n",
    "plt.arrow(-t * a1[0], -t * a1[1], 2 * t * a1[0], 2 * t * a1[1], head_width=0.2, head_length=0.2, fc='black', ec='black', label=\"a1 (First Canonical Direction)\")\n",
    "plt.arrow(-t * a2[0], -t * a2[1], 2 * t * a2[0], 2 * t * a2[1], head_width=0.2, head_length=0.2, fc='black', ec='black', label=\"a2 (Second Canonical Direction)\")\n",
    "\n",
    "# Add dashed lines for original axes\n",
    "plt.axhline(0, color='gray', linestyle='dashed')\n",
    "plt.axvline(0, color='gray', linestyle='dashed')\n",
    "\n",
    "# Projection of points onto Fisher's directions\n",
    "plt.scatter(proj_a1[:, 0], proj_a1[:, 1], c=color_species[y], alpha=0.5)\n",
    "plt.scatter(proj_a2[:, 0], proj_a2[:, 1], c=color_species[y], alpha=0.5)\n",
    "\n",
    "# Labels\n",
    "plt.xlabel(\"Sepal Length\")\n",
    "plt.ylabel(\"Sepal Width\")\n",
    "plt.title(\"Projection on Fisher's Canonical Directions\")\n",
    "plt.grid(True)\n",
    "plt.ylim(-8,8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1749562546975,
     "user": {
      "displayName": "Emanuele Alberti",
      "userId": "01048477993232507094"
     },
     "user_tz": -120
    },
    "id": "r5kIIhOeIU-A",
    "outputId": "0b956df3-0a93-4753-f230-0148f6714ea6"
   },
   "outputs": [],
   "source": [
    "# Compute the angle between a1 and a2\n",
    "dot_product = np.dot(a1, a2)\n",
    "angle_radians = np.arccos(dot_product)  # Angle in radians\n",
    "angle_degrees = np.degrees(angle_radians)  # Convert to degrees\n",
    "\n",
    "angle_degrees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mqgnqwrAO08D"
   },
   "source": [
    "Let's compare the projection on LDA axes with the one on PCA axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "executionInfo": {
     "elapsed": 333,
     "status": "ok",
     "timestamp": 1749562547308,
     "user": {
      "displayName": "Emanuele Alberti",
      "userId": "01048477993232507094"
     },
     "user_tz": -120
    },
    "id": "F48Iu4UVO0VT",
    "outputId": "eeca7f88-1f08-4caa-acdd-723291cf70ba"
   },
   "outputs": [],
   "source": [
    "# Perform PCA on the original data\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_iris)  # PCA-transformed coordinates\n",
    "\n",
    "pca1, pca2 = pca.components_\n",
    "\n",
    "# Normalize PCA directions for visualization\n",
    "pca1 /= np.linalg.norm(pca1)\n",
    "pca2 /= np.linalg.norm(pca2)\n",
    "\n",
    "# Compute projections onto PCA directions in the original space\n",
    "proj_pca1 = np.outer(X_iris @ pca1, pca1) / np.sum(pca1 ** 2)\n",
    "proj_pca2 = np.outer(X_iris @ pca2, pca2) / np.sum(pca2 ** 2)\n",
    "\n",
    "# Compute class means in original space\n",
    "class_means_pca = np.array([X_iris[y_iris == i].mean(axis=0) for i in range(3)])\n",
    "\n",
    "# Plot: Projection on PCA Directions (Original Space)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(X_iris[:, 0], X_iris[:, 1], c=color_species[y_iris], alpha=0.5, label=\"Data\")\n",
    "plt.scatter(class_means_pca[:, 0], class_means_pca[:, 1], c=color_species, marker=\"X\", s=100, edgecolors=\"black\", label=\"Class Means\")\n",
    "\n",
    "# Scale factor for better visibility\n",
    "t = 5\n",
    "\n",
    "# Arrows for PCA directions\n",
    "plt.arrow(-t * pca1[0], -t * pca1[1], 2 * t * pca1[0], 2 * t * pca1[1], head_width=0.2, head_length=0.2, fc='black', ec='black', label=\"PC1 (First Principal Component)\")\n",
    "plt.arrow(-t * pca2[0], -t * pca2[1], 2 * t * pca2[0], 2 * t * pca2[1], head_width=0.2, head_length=0.2, fc='black', ec='black', label=\"PC2 (Second Principal Component)\")\n",
    "\n",
    "# Add dashed lines for original axes\n",
    "plt.axhline(0, color='gray', linestyle='dashed')\n",
    "plt.axvline(0, color='gray', linestyle='dashed')\n",
    "\n",
    "# Projection of points onto PCA directions\n",
    "plt.scatter(proj_pca1[:, 0], proj_pca1[:, 1], c=color_species[y_iris], alpha=0.5)\n",
    "plt.scatter(proj_pca2[:, 0], proj_pca2[:, 1], c=color_species[y_iris], alpha=0.5)\n",
    "\n",
    "# Labels\n",
    "plt.xlabel(\"Sepal Length\")\n",
    "plt.ylabel(\"Sepal Width\")\n",
    "plt.title(\"Projection on PCA Principal Components\")\n",
    "plt.grid(True)\n",
    "plt.ylim(-8, 8)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1749562547314,
     "user": {
      "displayName": "Emanuele Alberti",
      "userId": "01048477993232507094"
     },
     "user_tz": -120
    },
    "id": "869JGy_-PV-s",
    "outputId": "ff9571c5-3cd5-473c-c063-305e59b998d3"
   },
   "outputs": [],
   "source": [
    "# Compute the angle between pca1 and pca2\n",
    "dot_product = np.dot(pca1, pca2)\n",
    "angle_radians = np.arccos(dot_product)  # Angle in radians\n",
    "angle_degrees = np.degrees(angle_radians)  # Convert to degrees\n",
    "\n",
    "angle_degrees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7hn2JEkxqlPB"
   },
   "source": [
    "# K-Neareast Neighbour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MtsfnJ9Bqxm2"
   },
   "source": [
    "## Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "executionInfo": {
     "elapsed": 3344,
     "status": "ok",
     "timestamp": 1749562550659,
     "user": {
      "displayName": "Emanuele Alberti",
      "userId": "01048477993232507094"
     },
     "user_tz": -120
    },
    "id": "emyACF1tqmkO",
    "outputId": "18b82069-484f-4c5e-90e2-b083a45c0b88"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Train a KNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)  # Using 5 neighbors\n",
    "knn.fit(X_iris[:, :2], y_iris)\n",
    "\n",
    "# Create a mesh grid for decision boundary\n",
    "x_min, x_max = X_iris[:, 0].min() - 0.1, X_iris[:, 0].max() + 0.1\n",
    "y_min, y_max = X_iris[:, 1].min() - 0.1, X_iris[:, 1].max() + 0.1\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200),\n",
    "                     np.linspace(y_min, y_max, 200))\n",
    "\n",
    "# Predict the class for each point in the grid\n",
    "Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Plot the decision boundary\n",
    "plt.figure()\n",
    "plt.contourf(xx, yy, Z, alpha=0.3, cmap='brg')\n",
    "\n",
    "# Plot the data points\n",
    "plt.scatter(X_iris[:, 0], X_iris[:, 1], c=y_iris, cmap='brg', edgecolor='k', s=30)\n",
    "\n",
    "# Legend for species\n",
    "handles = [\n",
    "    mpatches.Patch(color=plt.get_cmap(\"brg\", 3)(0), label='Setosa'),\n",
    "    mpatches.Patch(color=plt.get_cmap(\"brg\", 3)(1), label='Versicolor'),\n",
    "    mpatches.Patch(color=plt.get_cmap(\"brg\", 3)(2), label='Virginica')\n",
    "]\n",
    "plt.legend(handles=handles, loc='upper right')\n",
    "\n",
    "# Labels and title\n",
    "plt.title(\"KNN Classification of Iris Sepal\")\n",
    "plt.xlabel(\"Sepal Length\")\n",
    "plt.ylabel(\"Sepal Width\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1749562550667,
     "user": {
      "displayName": "Emanuele Alberti",
      "userId": "01048477993232507094"
     },
     "user_tz": -120
    },
    "id": "vzNENHskrAKP",
    "outputId": "c68d30cf-0ca0-4214-f338-c8a54a7cfcb0"
   },
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_iris[:, :2])\n",
    "\n",
    "conf_matrix = confusion_matrix(y_iris, y_pred)\n",
    "\n",
    "# Compute APER (Apparent Error Rate)\n",
    "aper = 1 - accuracy_score(y_iris, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nApparent Error Rate (APER): {:.4f}\".format(aper))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OLhJf-b1rOU6"
   },
   "source": [
    "## Banknotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1749562550673,
     "user": {
      "displayName": "Emanuele Alberti",
      "userId": "01048477993232507094"
     },
     "user_tz": -120
    },
    "id": "MAP6Qd-HrPom",
    "outputId": "c46ab463-9ceb-4aa5-da18-ba8bc70be3aa"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Define cost-sensitive priors\n",
    "c_tf = 10    # Cost of accepting a false banknote\n",
    "c_ft = 0.05  # Cost of rejecting a true banknote\n",
    "pf   = 0.001 # Prior probability of a false banknote\n",
    "pt   = 1 - pf # Prior probability of a true banknote\n",
    "\n",
    "# Compute adjusted priors\n",
    "num = c_tf * pf + c_ft * pt  # Normalization factor\n",
    "p_true_c = (pt * c_ft) / num\n",
    "p_false_c = (pf * c_tf) / num\n",
    "prior_c = [p_true_c, p_false_c]\n",
    "\n",
    "# Ensure labels match the priors\n",
    "desired_order = [\"true\", \"false\"]  # Order must be consistent with priors\n",
    "banknotes = np.vstack([true_data, false_data])\n",
    "vf = np.array([\"true\"]*len(true_data) + [\"false\"]*len(false_data), dtype=object)\n",
    "y_encoded = np.array([desired_order.index(label) for label in vf])  # Encode labels\n",
    "\n",
    "\n",
    "# Train KNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(banknotes, y_encoded)\n",
    "\n",
    "# Retrieve neighbors for each test sample\n",
    "distances, indices = knn.kneighbors(banknotes)\n",
    "\n",
    "# Custom decision function that adjusts for priors\n",
    "y_pred_adjusted = []\n",
    "for i in range(len(banknotes)):\n",
    "    neighbors = y_encoded[indices[i]]  # Get nearest neighbors' classes\n",
    "    vote_counts = Counter(neighbors)  # Count occurrences of each class\n",
    "\n",
    "    # Adjust votes based on priors\n",
    "    weighted_votes = {cls: count * prior_c[cls] for cls, count in vote_counts.items()}\n",
    "\n",
    "    # Assign the class with the highest weighted vote\n",
    "    adjusted_prediction = max(weighted_votes, key=weighted_votes.get)\n",
    "    y_pred_adjusted.append(adjusted_prediction)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(y_encoded, y_pred_adjusted)\n",
    "\n",
    "\n",
    "# Print results\n",
    "print(\"Confusion Matrix (With Adjusted Priors):\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1749562550678,
     "user": {
      "displayName": "Emanuele Alberti",
      "userId": "01048477993232507094"
     },
     "user_tz": -120
    },
    "id": "6Vi4MAebr7_z",
    "outputId": "df794ada-6c09-447d-c02f-eea160fd74ea"
   },
   "outputs": [],
   "source": [
    "# TODO: compute APER\n",
    "aper = 1 - accuracy_score(y_encoded, y_pred_adjusted)\n",
    "aper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "executionInfo": {
     "elapsed": 2345,
     "status": "ok",
     "timestamp": 1749562553024,
     "user": {
      "displayName": "Emanuele Alberti",
      "userId": "01048477993232507094"
     },
     "user_tz": -120
    },
    "id": "yan2gPHvtayI",
    "outputId": "7b99d6af-69c7-4433-fb62-79504e968ea5"
   },
   "outputs": [],
   "source": [
    "# TODO: plot decision boundaries\n",
    "# Create a mesh grid for decision boundary\n",
    "x_min, x_max = banknotes[:, 0].min() - 0.1, banknotes[:, 0].max() + 0.1\n",
    "y_min, y_max = banknotes[:, 1].min() - 0.1, banknotes[:, 1].max() + 0.1\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200),\n",
    "                     np.linspace(y_min, y_max, 200))\n",
    "\n",
    "# Predict the class for each point in the grid\n",
    "Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Plot the decision boundary\n",
    "plt.figure()\n",
    "plt.contourf(xx, yy, Z, alpha=0.3, cmap='brg')\n",
    "\n",
    "# Plot the data points\n",
    "plt.scatter(banknotes[:, 0], banknotes[:, 1], c=y_encoded, cmap='brg', edgecolor='k', s=30)\n",
    "\n",
    "# Legend for species\n",
    "handles = [\n",
    "    mpatches.Patch(color=plt.get_cmap(\"brg\", 2)(0), label='True'),\n",
    "    mpatches.Patch(color=plt.get_cmap(\"brg\", 2)(1), label='False')\n",
    "]\n",
    "plt.legend(handles=handles, loc='upper right')\n",
    "\n",
    "# Labels and title\n",
    "plt.title(\"KNN Classification of Banknotes\")\n",
    "plt.xlabel(\"V1\")\n",
    "plt.ylabel(\"V2\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1Ac7Fbs3Ay3U69bxYq7Mw_Hw_Mp2otukk",
     "timestamp": 1749560439733
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
